<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>My New Hugo Site</title>
    <link>http://localhost:1313/</link>
    <description>My New Hugo Site</description>
    <generator>Hugo 0.143.1 &amp; FixIt v0.3.17-8b402129</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 Feb 2025 00:05:27 -0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CS184 HW1 Writeup</title>
      <link>http://localhost:1313/posts/eeccd09/</link>
      <pubDate>Sat, 08 Feb 2025 00:05:27 -0800</pubDate>
      <guid>http://localhost:1313/posts/eeccd09/</guid>
      <category domain="http://localhost:1313/categories/cs184/">CS184</category>
      <description>&lt;h2 id=&#34;write-up-for-hw1&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Write up for HW1&lt;/span&gt;&#xA;  &lt;a href=&#34;#write-up-for-hw1&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;blockquote&gt;&#xA;&lt;p&gt;Group members: Xize Duan, Phoenix Ye.&#xA;Link to the page itself: &lt;a href=&#34;https://alexdwastaken.github.io/Blog/posts/eeccd09/index.html&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;https://alexdwastaken.github.io/Blog/posts/eeccd09/index.html&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;overview&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Overview&lt;/span&gt;&#xA;  &lt;a href=&#34;#overview&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;h2 id=&#34;question-1&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Question 1&lt;/span&gt;&#xA;  &lt;a href=&#34;#question-1&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;To rasterize a triangle, what we fisrt did is to perform a point-in-triangle test. The test is accomplished by performing a cross product $(p_1-p_0)\times (p_2-p_1) \cdot k$. If the result is negative, then the winding order is clockwise, otherwise counterclockwise. The final result will never be zero for a well-defined triangle.&#xA;We fisrt assume a counter-clockwise winding order.&#xA;Then the following is the condition for point inside triangle:&lt;/p&gt;&#xA;&lt;p&gt;$$&#xA;(y1 - y0) (x - x0) + (x1 - x0) (y - y0) \geq 0 \newline&#xA;(y2 - y1) (x - x1) + (x2 - x1) (y - y1) \geq 0 \newline&#xA;(y0 - y2) (x - x2) + (x0 - x2) (y - y2) \geq 0&#xA;$$&lt;/p&gt;&#xA;&lt;p&gt;If the winding order is clockwise, simply change the direction of the signs.&lt;/p&gt;&#xA;&lt;p&gt;The next thing we do is to enumerate across every row in the bounding box of the triangle, and color the pixel if the point inside the triangle. What we did to optimize this operation is that we keep track whether we have left the triangle. If we have left the triangle, then the rest of the picture on this row will never skip to the next row, so it is safe to escape to the next row.&lt;/p&gt;&#xA;&lt;p&gt;We timed the rendering time of the dragon picture. The naive method which we enumerated every pixel in the bounding box took around 0.0078 second on average, and the one which we kept track of whether we have left the triangle took 0.0067 second on average.&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-2&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Question 2&lt;/span&gt;&#xA;  &lt;a href=&#34;#question-2&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;In summary, the supersampling algorithm improves image quality by working in a higher-resolution space and then averaging down to the final image. The modifications sums up to three steps—using a larger sample buffer, scaling coordinates, and adding a resolve step.&lt;/p&gt;&#xA;&lt;p&gt;We changed the size of sample buffer each time. One subtle difference is that if the total image is supersampled by $n$, then its coordinate is only scaled by $\sqrt{n}$, which is crucial in correctly sample everything. During the sampling process, instead of marking an entire pixel as either inside or outside, we check multiple subpixel sample locations especially on edge places.. For example, when we supersample by a factor of 4, the coordinates are scaled by a factor of 2. We also modified the function that&amp;rsquo;s used to erase and rewrite sample buffer by a factor of $n$.&lt;/p&gt;&#xA;&lt;p&gt;For each triangle, we write this into a bigger version of the sample buffer. When finally writing the sampled image onto the frame buffer, we take average of the corresponding pixel values to resolve to the final value. By capturing more detail about how a primitive covers a pixel, supersampling reduces the jagged edges (aliasing) that would otherwise appear when a pixel’s single sample is forced into a binary decision.&lt;/p&gt;&#xA;&lt;p&gt;Below are two examples of the rendering results of &lt;code&gt;basic/test4.svg&lt;/code&gt; under different parameters.&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Samplerate = 1&lt;/th&gt;&#xA;          &lt;th&gt;Samplerate = 4&lt;/th&gt;&#xA;          &lt;th&gt;Samplerate = 4&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1.png&#34; alt=&#34;Q2_1&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1.png?size=large 2x&#34; data-title=&#34;Q2_1&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4.png&#34; alt=&#34;Q2_4&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4.png?size=large 2x&#34; data-title=&#34;Q2_4&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16.png&#34; alt=&#34;Q2_16&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16.png?size=large 2x&#34; data-title=&#34;Q2_16&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Samplerate = 1&lt;/th&gt;&#xA;          &lt;th&gt;Samplerate = 4&lt;/th&gt;&#xA;          &lt;th&gt;Samplerate = 4&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1-2.png&#34; alt=&#34;Q2_1-2&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1-2.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1-2.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_1-2.png?size=large 2x&#34; data-title=&#34;Q2_1-2&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4-2.png&#34; alt=&#34;Q2_4-2&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4-2.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4-2.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_4-2.png?size=large 2x&#34; data-title=&#34;Q2_4-2&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16-2.png&#34; alt=&#34;Q2_16-2&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16-2.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16-2.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ2_16-2.png?size=large 2x&#34; data-title=&#34;Q2_16-2&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;We observed that, as the sample rate goes up, the thin angle becomes less sharp but more continuous, and better represents the &amp;ldquo;real&amp;rdquo; triangle. This is because a higher sample rate increases the resolution of the sampled data, allowing for a more accurate approximation of the true shape of the triangle. At lower sample rates, the sampled points are more sparsely distributed, leading to a jagged or stepped representation of sharp angles. As the sample rate increases, more points are captured along the edges, smoothing out the transitions and reducing aliasing effects, which results in a more continuous and precise representation of the original shape.&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-3&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Question 3&lt;/span&gt;&#xA;  &lt;a href=&#34;#question-3&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;We implemented the transform functions by generating corresponding transform matrix. We altered the svg so that the little people is now doing exercies by stretching their arms.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-15%20at%2010.29.43%E2%80%AFPM.png&#34; alt=&#34;Screenshot 2025-02-15 at 10.29.43 PM&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-15%20at%2010.29.43%E2%80%AFPM.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-15%20at%2010.29.43%E2%80%AFPM.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-15%20at%2010.29.43%E2%80%AFPM.png?size=large 2x&#34; data-title=&#34;Screenshot 2025-02-15 at 10.29.43 PM&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;p&gt;The SVG file can be downloaded here. &lt;a href=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/my_robot.svg&#34;target=&#34;_blank&#34; rel=&#34;external nofollow noopener noreferrer&#34;&gt;Q3_svg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/my_robot.svg&#34; alt=&#34;Q3_svg&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/my_robot.svg?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/my_robot.svg?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/my_robot.svg?size=large 2x&#34; data-title=&#34;Q3_svg&#34; class=&#34;suffix-invalid suffix-invalid__small suffix-invalid__large&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-4&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Question 4&lt;/span&gt;&#xA;  &lt;a href=&#34;#question-4&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;h2 id=&#34;explanation&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Explanation&lt;/span&gt;&#xA;  &lt;a href=&#34;#explanation&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Barycentric coordinates are a way of describing a point&amp;rsquo;s position inside a triangle (or a higher-dimensional simplex) using weighted averages of the triangle’s vertices. Every point inside the triangle is represented by three numbers (weights), corresponding to the triangle&amp;rsquo;s vertices A, B, C. The berycentric coordinates can be intepreted as the ratio of the area of a small triangles with respect to the area of the full triangle. The closer P is to a vertex, the larger the corresponding subtriangle’s area, and thus the larger the associated barycentric coordinate. See the picture below for a detailed illustration.&lt;/p&gt;&#xA;&lt;img src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsimage-20250215224622798.png&#34; alt=&#34;image-20250215224622798&#34; style=&#34;zoom:33%;&#34; /&gt;&#xA;&lt;p&gt;Berycentric coordinates can effectively be used for intropolation. For a point with coordinates ($\lambda_A, \lambda_B, \lambda_C$), its color can be intepreted as ($\lambda_A \cdot c_A+ \lambda_B \cdot c_B, \lambda_C\cdot c_C$). See the picture below for a illustration of a triangle interpolated with berycentric coordinates.&lt;/p&gt;&#xA;&lt;img src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ4_demonestration.png&#34; alt=&#34;Q4_demonestration&#34; style=&#34;zoom:50%;&#34; /&gt;&#xA;&lt;h2 id=&#34;screenshot&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Screenshot&lt;/span&gt;&#xA;  &lt;a href=&#34;#screenshot&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Here is a png screenshot of &lt;code&gt;svg/basic/test7.svg&lt;/code&gt; with default viewing parameters and sample rate 1.&lt;/p&gt;&#xA;&lt;img src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ4_color_wheel.jpg&#34; alt=&#34;Q4_color_wheel&#34; style=&#34;zoom:50%;&#34; /&gt;&#xA;&lt;h2 id=&#34;question-5&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Question 5&lt;/span&gt;&#xA;  &lt;a href=&#34;#question-5&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;h2 id=&#34;explanation-1&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Explanation&lt;/span&gt;&#xA;  &lt;a href=&#34;#explanation-1&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Pixel sampling is the process of determining the color of a pixel by fetching texture data from a texture map. When implementing texture mapping, I used pixel sampling to fetch the correct texel color based on texture coordinates (u,v), which are continuous values ranging from 0 to 1. The range of u, v needs to be converted to the actual coordinates of the mipmap, or otherwise we will be constantly sampling the (0, 0) pixel. My inplementation can be factorized into two steps: Frrstly, we mapped the (u, v) coordinates to the texture image’s pixel grid. After that, colors can be effectively fetched from the uv coordinates.&lt;/p&gt;&#xA;&lt;p&gt;Now we explain the difference of the two sample methods. The nearest method simply rounds the non-integer coordinates to the nearest integer values, while bilinear method interpolates color from the four nearest pixels. These can be formulated as follows:&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Nearest Neighbor Sampling&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Convert (u, v) to texture space:&lt;br&gt;&#xA;$$&#xA;x = \text{round}(u \times \text{texture width})&#xA;$$&#xA;$$&#xA;y = \text{round}(v \times \text{texture height})&#xA;$$&lt;/li&gt;&#xA;&lt;li&gt;Fetch the texel at $(x, y)$.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Bilinear Sampling&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Compute the surrounding texel indices and their fractional offsets:&lt;br&gt;&#xA;$$&#xA;x = u \times \text{texture width}, \quad y = v \times \text{texture height}&#xA;$$&#xA;$$&#xA;x_0 = \lfloor x \rfloor, \quad x_1 = x_0 + 1&#xA;$$&#xA;$$&#xA;y_0 = \lfloor y \rfloor, \quad y_1 = y_0 + 1&#xA;$$&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Retrieve the four texels at $(x_0, y_0)$, $(x_0, y_1)$, $(x_1, y_0)$, $(x_1, y_1)$.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Perform linear interpolation first along x, then along y.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;comparison&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Comparison&lt;/span&gt;&#xA;  &lt;a href=&#34;#comparison&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Here are the example renderings of different methods. Notice the gradient int the transition, how bilinear is more smooth, and how supersampling further enhances the render results. Also, nearest  sampling renders a little faster.&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;          &lt;th&gt;Nearest&lt;/th&gt;&#xA;          &lt;th&gt;Bilinear&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1 Sample&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_1.png&#34; alt=&#34;Q5_N_1&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_1.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_1.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_1.png?size=large 2x&#34; data-title=&#34;Q5_N_1&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_1.png&#34; alt=&#34;Q5_Bi_1&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_1.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_1.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_1.png?size=large 2x&#34; data-title=&#34;Q5_Bi_1&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16 Samples&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_16.png&#34; alt=&#34;Q5_N_16&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_16.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_16.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_N_16.png?size=large 2x&#34; data-title=&#34;Q5_N_16&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_16.png&#34; alt=&#34;Q5_Bi_16&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_16.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_16.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Bi_16.png?size=large 2x&#34; data-title=&#34;Q5_Bi_16&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;In the following example, bilinear clearly defeats nearest. The color of nearest sampling has visible jaggies, while the bilinear methods is way more smooth.&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Bilinear&lt;/th&gt;&#xA;          &lt;th&gt;Nearest&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_Bi.png&#34; alt=&#34;Q5_Comparison_Bi&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_Bi.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_Bi.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_Bi.png?size=large 2x&#34; data-title=&#34;Q5_Comparison_Bi&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_N.png&#34; alt=&#34;Q5_Comparison_N&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_N.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_N.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsQ5_Comparison_N.png?size=large 2x&#34; data-title=&#34;Q5_Comparison_N&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;relative-differences&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Relative Differences&lt;/span&gt;&#xA;  &lt;a href=&#34;#relative-differences&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;The difference of the two methods can be summed as follows:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Nearest sampling is fast but produces rough, pixelated results.&lt;/li&gt;&#xA;&lt;li&gt;Bilinear sampling smooths textures but requires more computation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For better quality, bilinear sampling is preferred, especially when textures are scaled.&lt;/p&gt;&#xA;&lt;p&gt;There will be a large difference when textures are magnified or skewed, in which nearest sampling will result in jaggies; also when there are high-frequency details, nearest will cause aliasing and bilinear will be a little better. In general, bilinear filtering improves visual quality in cases of scaling and transformation, while nearest sampling retains sharp texel boundaries but can lead to noticeable artifacts.&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-6&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Question 6&lt;/span&gt;&#xA;  &lt;a href=&#34;#question-6&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;h2 id=&#34;explanation-2&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Explanation&lt;/span&gt;&#xA;  &lt;a href=&#34;#explanation-2&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Level sampling is a technique used in texture mapping to determine the appropriate level of detail (LOD) for a texture based on the screen-space size of the mapped surface. Instead of directly using a high-resolution texture for all cases (results in aliasing), level sampling selects a lower-resolution version of the texture when the object is far away or viewed at a sharp angle. This helps maintain visual quality and performance because it is equivalent to pre-apply a low-resolution box filter.&lt;/p&gt;&#xA;&lt;p&gt;The idea is to precompute multiple levels of a texture where each level is a downsampled version of the original texture. During rendering, the appropriate level is chosen based on how much the texture is being scaled or minified.&lt;/p&gt;&#xA;&lt;p&gt;Our realization can be broken down into three steps. Firstly, compute the correspodning mipmaps. Then, according to the transformation and scaling factor, chooes the mipmap to sample from. At last, we fetch the color from the correponding mipmaps.&lt;/p&gt;&#xA;&lt;h2 id=&#34;comparison-1&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Comparison&lt;/span&gt;&#xA;  &lt;a href=&#34;#comparison-1&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Here’s a comparison of the tradeoffs between different sampling methods.&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Technique&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Speed&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Memory Usage&lt;/strong&gt;&lt;/th&gt;&#xA;          &lt;th&gt;&lt;strong&gt;Antialiasing Power&lt;/strong&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Pixel Sampling&lt;/td&gt;&#xA;          &lt;td&gt;Fast (samples one texture level at a time)&lt;/td&gt;&#xA;          &lt;td&gt;Low (only needs one texture fetch)&lt;/td&gt;&#xA;          &lt;td&gt;Low (prone to aliasing, especially at minified scales)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Level Sampling&lt;/td&gt;&#xA;          &lt;td&gt;Moderate (needs to compute LOD and may interpolate between MIP levels)&lt;/td&gt;&#xA;          &lt;td&gt;Moderate (requires multiple MIP map levels)&lt;/td&gt;&#xA;          &lt;td&gt;Good (reduces aliasing caused by minification)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Supersampling&lt;/td&gt;&#xA;          &lt;td&gt;Slow (increases rendering cost significantly)&lt;/td&gt;&#xA;          &lt;td&gt;High (multiple texture fetches per pixel)&lt;/td&gt;&#xA;          &lt;td&gt;Excellent (best at reducing jagged edges and flickering)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;To sum up, Pixel Sampling is the fastest and most memory-efficient but can introduce aliasing, especially at extreme minifications or magnifications; Level Sampling balances performance and quality by using precomputed MIP maps, reducing aliasing without a massive performance hit, and Supersampling provides the highest quality but at the cost of significant performance and memory usage.&lt;/p&gt;&#xA;&lt;h2 id=&#34;demonestration&#34; class=&#34;heading-element&#34;&gt;&lt;span&gt;Demonestration&lt;/span&gt;&#xA;  &lt;a href=&#34;#demonestration&#34; class=&#34;heading-mark&#34;&gt;&#xA;    &lt;svg class=&#34;octicon octicon-link&#34; viewBox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path d=&#34;m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&lt;p&gt;Here is a set of comparison of for sampling methods where we mainly focused on antialiasing power with pixel inspector on the upper-right corner. (Photo credit: Armand Khoury from Unsplash).&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;&lt;/th&gt;&#xA;          &lt;th&gt;P_NEAREST&lt;/th&gt;&#xA;          &lt;th&gt;P_LINEAR&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;L_ZERO&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.07%E2%80%AFAM.png&#34; alt=&#34;Screenshot 2025-02-16 at 12.01.07 AM&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.07%E2%80%AFAM.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.07%E2%80%AFAM.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.07%E2%80%AFAM.png?size=large 2x&#34; data-title=&#34;Screenshot 2025-02-16 at 12.01.07 AM&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.11%E2%80%AFAM.png&#34; alt=&#34;Screenshot 2025-02-16 at 12.01.11 AM&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.11%E2%80%AFAM.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.11%E2%80%AFAM.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.11%E2%80%AFAM.png?size=large 2x&#34; data-title=&#34;Screenshot 2025-02-16 at 12.01.11 AM&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;L_NEAREST&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.00%E2%80%AFAM.png&#34; alt=&#34;Screenshot 2025-02-16 at 12.01.00 AM&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.00%E2%80%AFAM.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.00%E2%80%AFAM.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.01.00%E2%80%AFAM.png?size=large 2x&#34; data-title=&#34;Screenshot 2025-02-16 at 12.01.00 AM&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.00.49%E2%80%AFAM.png&#34; alt=&#34;Screenshot 2025-02-16 at 12.00.49 AM&#34; srcset=&#34;https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.00.49%E2%80%AFAM.png?size=small, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.00.49%E2%80%AFAM.png?size=medium 1.5x, https://raw.githubusercontent.com/AlexDWasTaken/blog-pics/main/picsScreenshot%202025-02-16%20at%2012.00.49%E2%80%AFAM.png?size=large 2x&#34; data-title=&#34;Screenshot 2025-02-16 at 12.00.49 AM&#34; style=&#34;background: url(/images/loading.min.svg) no-repeat center;&#34; onload=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}this.dataset.lazyloaded=&#39;&#39;;&#34; onerror=&#34;this.title=this.dataset.title;for(const i of [&#39;style&#39;, &#39;data-title&#39;,&#39;onerror&#39;,&#39;onload&#39;]){this.removeAttribute(i);}&#34;/&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;</description>
    </item>
  </channel>
</rss>
